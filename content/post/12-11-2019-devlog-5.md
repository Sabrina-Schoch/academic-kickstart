---
title: Devlog 5
summary: Chatbot problems
date: 2019-11-12

reading_time: false
profile: false
comments: false

header:
  caption: ""
  image: ""

authors: ["admin"]

---

I created a test Chatbot on Snatchbot today. I read the Emotive Project's tutorial on building a chatbot and played with the different contexts and models for discussion. There are several premade models for chatbots, but many of Snatchbot's models are designed for data collection buisness models, rather than academic, educational or entertainmnet purposes. 

Even following the tutorial, creating a chatbot is not intuitive. Snatchbot and Emotive Project's tutorial make the steps easy to follow, but neither speak directly to my purposes and are thus inherently problematic. I want to create an interaction between an AI prison guard and a human engaging as a prisoner. Many of the models for the chatbot are formatted on the "if/then" framework--meaning if the chat participant says "X" then the chatbot says or does "Y." It is not formatted with the participant with agency--the context is created by the chatbot for the participant to engage in.

One problem is that I can only think of so many *logical* responses to accusations of lesbianism and conseuqential imprisonment in the ephemeral and intangible digital environment of a chatroom. What if a participant refuses to respond or simply clicks away from the chat, enacting their individual agency? What about *emotional* responses such as incoherent keyboard smashes? What if a participant responds in a language other than English? What if their verbiage is different to mine or they use a synonym to my coded language? 

The prescribed model accounts for some of these scenarios, such as a participants refusal to respond. However, the dictatorial environment I am attempting to create is incompatible with the anonymity, privilege and agency of the internet and digital engagement. This creates an esoteric experience and engages a specific audience.

A potential workaround for the problem of agency is to give the participant a variety of pre-written options when replying. While a pre-written response reduces the agency of self-expression and perpetuates an authoritarian envrionment, the participant maintains the passive agency of choosing between scenarios or reponses in the if X then Y prescriptive model. 

Ideally, I would format the chatbot in one of two other directions.

One improved model is an automated conversation between two chatbots. The human participant would either passively engage through observing the conversation, or choose the interaction and response between the bots.
