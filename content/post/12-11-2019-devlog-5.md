---
title: Devlog 5
summary: Chatbot problems
date: 2019-11-12

reading_time: false
profile: false
comments: false

header:
  caption: ""
  image: ""

authors: ["admin"]

---

I created a test Chatbot on Snatchbot today. I read the Emotive Project's tutorial on building a chatbot and played with the different contexts and models for discussion. There are several premade models for chatbots, but many of Snatchbot's models are designed for data collection buisness models, rather than academic, educational or entertainmnet purposes. 

Even following the tutorial, creating a chatbot is not intuitive. Snatchbot and Emotive Project's tutorial make the steps easy to follow, but neither speak directly to my purposes and are thus inherently problematic. I want to create an interaction between an AI prison guard and a human engaging as a prisoner. Many of the models for the chatbot are formatted on the "if/then" framework--meaning if the chat participant says "X" then the chatbot says or does "Y." It is not formatted with the participant with agency--the context is created by the chatbot for the participant to engage in.

One problem is that I can only think of so many *logical* responses to accusations of lesbianism and conseuqential imprisonment in the ephemeral and intangible digital environment of a chatroom. What if a participant refuses to respond or simply clicks away from the chat, enacting their individual agency? What about *emotional* responses such as incoherent keyboard smashes? What if a participant responds in a language other than English? What if their verbiage is different to mine or they use a synonym to my coded language? 

The model accounts for some of these scenarios, such as a participants refusal to respond. However, the dictatorial environment I am *attempting* to recreate is incompatible with the anonymity, privilege and agency of the internet and digital engagement. 
