---
title: Devlog 5
summary: Chatbot problems
date: 2019-11-12

reading_time: false
profile: false
comments: false

header:
  caption: ""
  image: ""

authors: ["admin"]

---

I created a test Chatbot on Snatchbot today. I read the Emotive Project's tutorial on building a chatbot and played with the different contexts and models for discussion. There are several premade models for chatbots, but many of Snatchbot's models are designed for data collection buisness models, rather than academic, educational or entertainmnet purposes. 

Even following the tutorial, creating a chatbot is not intuitive. Snatchbot and Emotive Project's tutorial make the steps easy to follow, but neither speak directly to my purposes and are thus inherently problematic. I want to create an interaction between an AI prison guard and a human engaging as a prisoner. Many of the models for the chatbot are formatted on the "if/then" framework--meaning if the chat participant says "X" then the chatbot says or does "Y." It is not formatted with the participant with agency--the context is created by the chatbot for the participant to engage in.

One problem is that I can only think of so many *logical* responses to accusations of lesbianism and conseuqential imprisonment in the ephemeral and intangible digital environment of a chatroom. What if a participant refuses to respond or simply clicks away from the chat, enacting their individual agency? What about *emotional* responses such as incoherent keyboard smashes? What if a participant responds in a language other than English? What if their verbiage is different to mine or they use a synonym to my coded language? 

The prescribed model accounts for some of these scenarios, such as a participants refusal to respond. However, the dictatorial environment I am attempting to create is incompatible with the anonymity, privilege and agency of the internet and digital engagement. This reduces the effiency of this experient, and reduces the ideal engagement to an esoteric participant.

A potential workaround for the problem of agency is to give the participant a variety of pre-written options when replying. While a pre-written response effectively reduces the agency of self-expression and perpetuates an authoritarian envrionment, the participant maintains passive agency by choosing between pre-written reponses. 

Ideally, I would format the chatbot in one of two other directions that decenter the if/then framework.

One direction is an automated conversation between two chatbots. The human participant would either passively engage through observing the conversation, or engage by selecting the pre-written response of each bot. A problem with this model is limited participant engagement compounded by more authoritarian agency.

Another potential model 
